{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Inspect Ballon Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import io\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.japan_roof import japan_roof\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to Ballon trained weights\n",
    "# You can download this file from the Releases page\n",
    "# https://github.com/matterport/Mask_RCNN/releases\n",
    "\n",
    "ckpt_number = 9245\n",
    "BALLON_WEIGHTS_PATH = \"../../logs/pascalvoc20200629T0141/mask_rcnn_pascalvoc_\" + str(ckpt_number) + \".h5\"  # TODO: update this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = japan_roof.PascalVOCConfig()\n",
    "JAPAN_ROOF_DIR = os.path.join(ROOT_DIR, \"/root/japan_roof_dataset_2000_solarpanel\")\n",
    "print(JAPAN_ROOF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "dataset = japan_roof.PascalVOCDataset()\n",
    "dataset.load_pascalvoc(JAPAN_ROOF_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set path to balloon weights file\n",
    "\n",
    "# Download file from the Releases page and set its path\n",
    "# https://github.com/matterport/Mask_RCNN/releases\n",
    "# weights_path = \"/path/to/mask_rcnn_balloon.h5\"\n",
    "\n",
    "# Or, load the last model you trained\n",
    "weights_path = model.find_last()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 면적 계산을 위한 행렬의 합을 계산\n",
    "\n",
    "def solution(arr1, arr2):\n",
    "    return [[c + d for c, d in zip(a, b)] for a, b in zip(arr1,arr2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c],\n",
    "                                  image[:, :, c])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "    \n",
    "result_save_dir = \"./inference_result_\" + str(ckpt_number) + \"/\"\n",
    "if not os.path.exists(result_save_dir):\n",
    "    os.mkdir(result_save_dir)\n",
    "\n",
    "cnt = 0\n",
    "# for path, dirs, files in os.walk(\"/root/japan_roof_dataset_2000_solarpanel/testtest/\"):\n",
    "for path, dirs, files in os.walk(\"/root/japan_roof_with_trees/\"):\n",
    "    for file in files:\n",
    "        cnt += 1\n",
    "        image_path = os.path.join(path, file)\n",
    "        image = io.imread(image_path)\n",
    "\n",
    "        # png 이미지에 alpha 채널이 있다면 제거 (640, 640 ,4)  >> (640, 640, 3)\n",
    "        if image.shape[-1] == 4:\n",
    "            image = image[..., :3]\n",
    "        \n",
    "        results = model.detect([image], verbose=1)\n",
    "        \n",
    "        # Display results\n",
    "        r = results[0]\n",
    "        \n",
    "        boxes = r['rois']\n",
    "        masks = r['masks']\n",
    "        class_ids = r['class_ids']\n",
    "        class_names = dataset.class_names\n",
    "        scores = r['scores']\n",
    "        show_bbox = True\n",
    "        show_mask = True\n",
    "        captions = None\n",
    "        \n",
    "        # Number of instances\n",
    "        N = boxes.shape[0]\n",
    "        print('number_of_instances : ', N)\n",
    "        if not N:\n",
    "            print(\"\\n*** No instances to display *** \\n\")\n",
    "        else:\n",
    "            assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "        # Generate random colors\n",
    "        colors = random_colors(N)\n",
    "\n",
    "        # Show area outside image boundaries.\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        masked_image = image.astype(np.uint32).copy()\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 이미지 사이즈의 Flase array 준비\n",
    "        flat_mask = np.full((640,640), False, dtype=bool)\n",
    "        trees_mask = np.full((640,640), False, dtype=bool)\n",
    "        solarpanel_mask = np.full((640,640), False, dtype=bool)\n",
    "        \n",
    "        for i in range(N):\n",
    "            float_color = colors[i]\n",
    "            color = [int(element * 255) for element in float_color]\n",
    "            \n",
    "            # Bounding box\n",
    "            if not np.any(boxes[i]):\n",
    "                # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "                continue\n",
    "            y1, x1, y2, x2 = boxes[i]\n",
    "\n",
    "            if show_bbox:\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
    "                \n",
    "                \n",
    "            # Label\n",
    "            if not captions:\n",
    "                class_id = class_ids[i]\n",
    "                score = scores[i] if scores is not None else None\n",
    "                label = class_names[class_id]\n",
    "                caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "            else:\n",
    "                caption = captions[i]\n",
    "            cv2.putText(image, caption, (x1, y1 + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "            \n",
    "            # Mask\n",
    "            mask = masks[:, :, i]\n",
    "            if show_mask:\n",
    "                masked_image = apply_mask(image, mask, color)\n",
    "            \n",
    "            if label == 'goodroof':\n",
    "                flat_mask = solution(flat_mask, mask)\n",
    "                \n",
    "            if label == 'trees':\n",
    "                trees_mask = solution(trees_mask, mask)\n",
    "\n",
    "            if label == 'solarpanel':\n",
    "                solarpanel_mask = solution(solarpanel_mask, mask)\n",
    "            \n",
    "#             print(\"label : \", label)\n",
    "#             print(\"instance mask size : \", np.count_nonzero(mask))\n",
    "#             print(\"flat_mask : \", np.count_nonzero(flat_mask))\n",
    "            \n",
    "            # 한 이미지의 마지막 루프 때 면적 계산결과를 표시\n",
    "            if i == N - 1:\n",
    "                flat_text = \"Ratio of Flat : \" + str(\"%0.2f\"%(np.count_nonzero(flat_mask)/409600)) # 640*640 = 409600\n",
    "                solarpanel_text = \"Ratio of solarpanel : \" + str(\"%0.2f\"%(np.count_nonzero(solarpanel_mask)/409600)) # 640*640 = 409600\n",
    "                trees_text = \"Ratio of trees : \" + str(\"%0.2f\"%(np.count_nonzero(trees_mask)/409600)) # 640*640 = 409600\n",
    "                \n",
    "                cv2.rectangle(masked_image, (380,580), (640,640), (255, 255, 255), (-1))\n",
    "                cv2.putText(masked_image, flat_text, (380, 580 + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "                cv2.putText(masked_image, solarpanel_text, (380, 580 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "                cv2.putText(masked_image, trees_text, (380, 580 + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "\n",
    "        cv2.imwrite(result_save_dir + file, masked_image)\n",
    "        print(\"Image count : \", cnt)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_mask = []\n",
    "mask1 = np.full((3,4), False, dtype=bool)\n",
    "\n",
    "mask2 = [\n",
    "    [False, False, False, False],\n",
    "    [True, False, False, True],\n",
    "    [False, False, False, False]\n",
    "    \n",
    "]\n",
    "\n",
    "print(mask1)\n",
    "mask1 = solution(mask1, mask2)\n",
    "print(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
